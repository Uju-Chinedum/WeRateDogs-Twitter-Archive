{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f4c22e0",
   "metadata": {},
   "source": [
    "# Wrangling Report on the WeRateDogs Twitter Archive Using Twitter's API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2717a774",
   "metadata": {},
   "source": [
    "Data Wrangling, the most important part of the Data Analysis but also the most tedious, is about gathering the data, assessing it and cleaning the unwanted data also fixing some\n",
    "errors in data. \n",
    "\n",
    "WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog. The goal of the project was to analyze and know the humour level of each breed of dog. Each dog is rated differently based on humour level with a common rating denominator of 10 but with weird levels of rating numerator, some higher than 10, but that is all part of the fun of the @dog_rates twitter account."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9479e5c",
   "metadata": {},
   "source": [
    "**Data Gathering**: The Udacity's `twitter-archive-enhanced.csv` file was gotten through manula download as stipulated while the `image-predictions.tsv` file was downloaded programmaticaly. I also downloaded the `twitter_json.txt` file from Twitter's API and it was a bot challenging since this was my first time working with APIs. The process of getting my keys were, in itself, another load of stress. From creating the Developer's account to answering cycles of questions but I finally got it. Once credentials were gotten and verified, a program had to be wriiten to get the Likes and Retweet Counts of the Tweet IDs in the `twitter-archive-enhanced.csv` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4aa9713",
   "metadata": {},
   "source": [
    "**Data Assessing**: The goal was to find, at minimum, eight quality and two tidiness issues. Mine were as follows:\n",
    "\n",
    "- Quality\n",
    "> - Remove retweets\n",
    "> - Dropping source column and rating_denominator column\n",
    "> - Renaming rating_numerator column\n",
    "> - Incorrect ratings\n",
    "> - Missing values for in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp\n",
    "> - Incorrect data types for tweet_id, in_reply_to_status_id, in_reply_to_user_id, timestamp, retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp\n",
    "> - Incorrect datatype for tweet_id\n",
    "> - Renaming every column\n",
    "> - Incorrect datatype for tweet_id\n",
    "\n",
    "- Tidiness\n",
    "> - Single variable split into multiple variables\n",
    "> - Combine likes and retweets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353d64bf",
   "metadata": {},
   "source": [
    "**Data Cleaning**: The approach to take to clean the the aforementioned issues was the _define-code-test_ method. It entails defining the problem, coding up the solution and the testing the results which were done individually for each problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3f182b",
   "metadata": {},
   "source": [
    "**Data Storing**: After Cleaning, the new master dataframe was stored as a `twitter-master-archive.csv` file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d426672",
   "metadata": {},
   "source": [
    "**Data Analysis and Visualization**: After everything, since the basis of this project was Data Wrangling, I did some basic analysis and visualization on the new master dataframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
